%# -*- coding: utf-8 -*-
% !TeX encoding = UTF-8 Unicode
% !TeX spellcheck = en_US
% !TeX TS-program = xelatex
%~ \XeTeXinputencoding "UTF-8"
% vim:ts=4:sw=4
%
% 以上设定默认使用 XeLaTex 编译，并指定 Unicode 编码，供 TeXShop 自动识别

%\documentclass[a4paper,10pt,twocolumn]{article}
\documentclass[letter,11pt,onecolumn]{book}
%\documentclass[letter,11pt,onecolumn,adobefonts]{ctexbook}

\newcommand{\doctitle}{mrnative -- run native software in an Hadoop/HPC environment}
\newcommand{\docauthor}{傅允辉}
\newcommand{\dockeywords}{Linux, mrnative, Hadoop}
\newcommand{\docsubject}{}

\newcommand{\usedefaultTWO}[2]{
\if\relax\detokenize{#2}\relax
  #1
\else
  #2
\fi
}

\newcommand{\usedefaultTHREE}[3]{
\if\relax\detokenize{#3}\relax
  \usedefaultTWO{#1}{#2}
\else
  #3
\fi
}

% 用于接受从 xelatex/pdflatex 通过参数 -jobname 传入的参数来判定编译何种语言的版本。
% \cnt 的三个参数分别为 en/zh/tw 的内容
\newcommand{\cnt}[3]{{#1}{#2}{#3}}
%\newcommand{\cnt}[3]{#1} % default en
\usepackage{ifthen}
\ifthenelse{\equal{\detokenize{lang-zh}}{\jobname}}{
  \renewcommand{\cnt}[3]{\usedefaultTWO{#1}{#2}}
}{
  \ifthenelse{\equal{\detokenize{lang-tw}}{\jobname}}{
    \renewcommand{\cnt}[3]{\usedefaultTHREE{#1}{#2}{#3}}
  }{
    % default en
    \renewcommand{\cnt}[3]{#1}
    %\renewcommand{\cnt}[3]{#2}
  }
}

\newcommand{\cnts}[3]{{#1} {#2}}

% 根据配置来设置中文环境
\newcommand\usefontspeczh[1]{#1} % use fontspec for zh_CN
\newcommand\charsetzhcn[1]{#1} % the charset encoding for zh_CN
\newcommand\formatzhcn[1]{#1} % the page format for zh_CN
\cnt{
\renewcommand\usefontspeczh[1]{}
\renewcommand\charsetzhcn[1]{}
\renewcommand\formatzhcn[1]{}
}{
%\renewcommand\usefontspeczh[1]{}
%\renewcommand\charsetzhcn[1]{}
%\renewcommand\formatzhcn[1]{}
}{
%\renewcommand\usefontspeczh[1]{}
%\renewcommand\charsetzhcn[1]{}
%\renewcommand\formatzhcn[1]{}
}
\input{cndoc.tex}


\newcommand\comments[1]{#1}
\renewcommand\comments[1]{}

\usepackage{xcolor}

\usepackage{amssymb}
%\usepackage{amsmath,amsfonts,amsthm}

\usepackage{array}
% table's multirow and multicolumn
\usepackage{multirow}

\usepackage{chapterbib}
\usepackage[sectionbib,super,square,sort&compress]{natbib}

%\usepackage[margin=1.8cm,nohead]{geometry}
\usepackage[margin=0.8in,nohead]{geometry}
%\usepackage[top=1in,bottom=1in,left=1.25in,right=1.25in]{geometry} % 设置页边距
%\setlength{\belowcaptionskip}{1em} % 设置caption之后的距离

%opening
\title{\doctitle}
\author{\docauthor}
%\date{2014-03}

\begin{document}

\maketitle
\tableofcontents


\input{chap-intro.tex}

\input{chap-appconv2dash.tex}
\input{chap-appwpapw.tex}
\input{chap-appns2.tex}


\appendix

\chapter{Media Basis}

\section{GOP, I, B, P Frame}

An MPEG "GOP" GOB (Group Of Pictures), starts with an "I" frame (Intra-coded picture, key frame),
follows with multiple "P" (Predicted picture) or "B" (Bi-predictive picture) frames.

I frame is like a conventional static image file, P-frames and B-frames hold only part of the image.

P frame holds only the changes from the \emph{previous} frame.

B frame holds the differences between the current frame and both the preceding and following frames.


\begin{figure}\centering
  \includegraphics[width=0.95\textwidth]{figures-appconv2dash/gop-ipb.png}
  \caption{Example of a GOP structure (\href{http://en.wikipedia.org/wiki/Inter_frame}{Wikipedia}).}\label{fig:gopipb}
\end{figure}

\section{参考}

\subsection{split media files}
How to split a video using FFMPEG so that each chunk starts with a key frame?
\url{http://stackoverflow.com/questions/14005110/how-to-split-a-video-using-ffmpeg-so-that-each-chunk-starts-with-a-key-frame}



1. Jan 30 at 6:25
The latest builds of FFMPEG include a new option "segment" which does exactly what I think you need.
\begin{lstlisting}[language=bash]
ffmpeg -i INPUT.mp4 -acodec copy -f segment -vcodec copy -reset_timestamps 1 -map 0 OUTPUT%d.mp4
\end{lstlisting}
This produces a series of numbered output files which are split into segments based on Key Frames. In my own testing, it's worked well, although I haven't used it on anything longer than a few minutes and only in MP4 format.



2. Jul 16 '13 at 22:58
Using a newer build of ffmpeg, can achieve this by using ffprobe and the ffmpeg segment muxer.

1.Use ffprobe and awk to identify the keyframes as close as possible to your desired chunk length.
\begin{lstlisting}[language=bash]
ffprobe -show_frames -select_streams v:0 -print_format csv **[SOURCE_VIDEO]** 2>&1 | grep -n frame,video,1 | awk 'BEGIN { FS="," } { print $1 " " $5 }' | sed 's/:frame//g' | awk 'BEGIN { previous=0; frameIdx=0; size=0; } { split($2,time,"."); current=time[1]; if (current-previous >= **[DURATION_IN_SECONDS]**){ a[frameIdx]=$1; frameIdx++; size++; previous=current;} } END { str=a[0]; for(i=1;i<size;i++) { str = str "," a[i]; } print str;}'
\end{lstlisting}
Where
\begin{lstlisting}[language=bash]
    [SOURCE_VIDEO] = path to video you want to segment
    [DURATION_IN_SECONDS] = desired segment length in seconds
\end{lstlisting}
The output is comma-delimited string of keyframes.

2.Use the keyframes output above as input to ffmpeg.
\begin{lstlisting}[language=bash]
ffmpeg -i [SOURCE_VIDEO] -codec copy -map 0 -f segment -segment_frames [OUTPUT_OF_STEP_1] [SEGMENT_PREFIX] _%03d.[SOURCE_VIDEO_EXTENSION]
\end{lstlisting}
Where
\begin{lstlisting}[language=bash]
    [SOURCE_VIDEO] = path to video you want to segment
    [OUTPUT_OF_STEP_1] = comma-delimited string of keyframes
    [SEGMENT_PREFIX] = name of segment output
    [SOURCE_VIDEO_EXTENSION] = extension of source video (e.g., mp4, mkv)
\end{lstlisting}



3. Dec 23 '12 at 18:17
Here is the solution that I could get to work:

As suggested by av501 and d33pika, I used ffprobe to find where the key frames are. Because ffprobe is very verbose and can take several seconds or even minutes to output all key frames and there is no way to scope the range of frames we want from a lengthy video, I proceed into 5 steps:

    Export a video chunk from the original file, around the double of the desired chunk size.
\begin{lstlisting}[language=bash]
ffmpeg -i source.wmv -ss 00:00:00 -t 00:00:06 -acodec copy -vcodec copy -async 1 -y  0001.wmv
\end{lstlisting}
    Use ffprobe to find where the keyframes are. Choose closest keyframe after desired chunk size.
\begin{lstlisting}[language=bash]
ffprobe -show_frames -select_streams v -print_format json=c=1 0001.wmv
\end{lstlisting}
    From the output of ffprobe get the \texttt{pkt\_dts\_time} of the frame just before that key frame.

    ffmpeg on the exported chunk of step 1, specifying the same input and output file, and specifying -ss 00:00:00 and -t [value found in step 3].
\begin{lstlisting}[language=bash]
ffmpeg -i 0001.wmv -ss 00:00:00 -t 00:00:03.1350000 -acodec copy -vcodec copy -async 1 -y 0001.wmv
\end{lstlisting}
    Restart at step 1, using -ss [cumulated sum of values found in step 3 over iterations].

Proceeding this way, I was able to have an efficient and robust way to split the video at key frames.



4. Dec 23 '12 at 14:11
Use ffprobe -show\_frames -pretty <stream> to identify the key frames.


5. Dec 23 '12 at 3:36
If you are willing to do some scripting and want I frames at a particular interval the one way to do it is

Run ffprobe and collect the locations of the I frames from the output
\begin{lstlisting}[language=bash]
ffprobe -show_streams
\end{lstlisting}
Run a series of -ss -t commands using the same script to get the chunks you desire.

You can then have your script decide minimum number of frames [say there are two I pictures within 10 frames of each other, you really don't want to be chunking it there].

\chapter{References}

Google MapReduce for C: Run Native Code in Hadoop
\url{http://google-opensource.blogspot.com/2015/02/mapreduce-for-c-run-native-code-in.html}



Cloud MapReduce -- A MapReduce implementation on Amazon Cloud OS
\url{https://code.google.com/p/cloudmapreduce/}


Apache Storm is a free and open source distributed realtime computation system.
\url{http://storm.apache.org/}

Apache Spark is a fast and general engine for large-scale data processing.
\url{http://spark.apache.org/}


\section{C/C++}


\href{http://hypertable.com/}{Hypertable} is a high performance, open source, massively scalable database modeled after Bigtable, Google's proprietary, massively scalable database.

\section{python}


\href{https://github.com/mfisk/filemap.git}{FileMap} is a file-based map-reduce system for data-parallel computation. (python)

\href{https://code.google.com/p/octopy/}{octopy} Easy MapReduce for Python

\href{https://github.com/michaelfairley/mincemeatpy.git}{mincemeatpy} Lightweight MapReduce in python (2013)

\href{http://heynemann.github.io/r3/}{r³} is a map reduce engine written in python using a redis backend. It's purpose is to be simple.


\href{http://discoproject.org/}{Disco} is a lightweight, open-source framework for distributed computing based on the MapReduce paradigm.



\url{https://wiki.python.org/moin/ParallelProcessing}
python Parallel Processing

\href{http://ipython.org/}{IPython} provides tools for interactive and parallel computing that are widely used in scientific computing, but can benefit any Python developer.

\section{Bash}

bashreduce (origin) \url{https://github.com/erikfrey/bashreduce.git}

improved bashreduce \url{https://github.com/dakusui/bredxbred.git},
or \url{https://github.com/rcrowley/bashreduce.git}. others, \href{https://github.com/jweslley/bashreduce.git}{jweslley}.



others:
\href{https://github.com/jasonMatney/BashMapReduce.git}{BashMapReduce},
\href{https://github.com/sorhus/bash-reduce.git}{bash-reduce},
\href{https://github.com/colestanfield/map-reduce.git}{map-reduce},
\href{https://github.com/argent0/mr-tools.git}{mr-tools},


\section{others}



\url{http://quantcast.github.io/qfs/}
Quantcast File System (QFS) is a high-performance, fault-tolerant, distributed file system developed to support MapReduce processing, or other applications reading and writing large files sequentially.

\href{https://rubygems.org/gems/mapredus}{mapredus}, simple mapreduce framework using redis and resque

\href{http://projects.camlcity.org/projects/plasma.html}{Plasma}: Distributed filesystem, key/value db, and map/reduce system. 2011


\href{http://mapreduce.sandia.gov/}{MapReduce-MPI Library} includes C++ and C interfaces callable from most hi-level languages, and also a Python wrapper


\href{http://sector.sourceforge.net/}{Sector/Sphere} is a system for distributed data storage, distribution, and processing. The system works on clusters of commodity computers. Sector provides client tools to access data stored in the system and API for the development of distributed data processing applications.

\href{http://skynet.rubyforge.org/}{Skynet} is an open source Ruby implementation of Google’s MapReduce framework


\href{https://code.google.com/p/httpmr/}{httpmr} A scalable data processing framework for people with web clusters


\href{https://code.google.com/p/qizmt/}{qizmt} is a mapreduce framework for executing and developing distributed computation applications on large clusters of Windows servers.




\href{https://code.google.com/p/cloudmapreduce/}{Cloud MapReduce} -- A MapReduce implementation on Amazon Cloud OS

\url{https://github.com/googlecloudplatform/appengine-mapreduce}
A library for running MapReduce jobs on App Engine




\url{https://github.com/documentcloud/cloud-crowd}
Write your scripts in Ruby, Works with Amazon EC2 and S3



\url{http://www.cse.ust.hk/gpuqp/Mars.html}
A MapReduce Framework on Graphics Processors


\url{https://github.com/ryanmcgrath/maprejuice}
javascript, node.js

\chapter{Source Code}

\begin{lstlisting}[language=bash]
ffprobe -show_streams
\end{lstlisting}


\end{document}



